{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yelpapi import YelpAPI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list to store dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call to search based on term=['cafes','restaurants','bars'] and \n",
    "# location=['Brooklyn,NY','Bronx, NY','Manhattan, NY','Queens, NY', 'Staten Island, NY'] \n",
    "# As we can only fetch 1000 rows at a time, try different combination( e.g: term= cafe and location=Manhattan,NY)\n",
    "\n",
    "# We run a for loop on the offset (pagination- Going from 1-50, 51-100...) and store our result in a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n",
      "The status code is 200\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from pprint import pprint\n",
    "\n",
    "#file = open('YelpAPI_Data.json', 'w+')\n",
    "api_key= #put your key\n",
    "url=\"https://api.yelp.com/v3/businesses/search\"\n",
    "# n=['Brooklyn,NY','Bronx, NY','Manhattan, NY','Queens, NY', 'Staten Island, NY']\n",
    "neighborhood= 'Manhattan, NY'\n",
    "\n",
    "for x in range(20):\n",
    "    params={'term':'bars','location':neighborhood,'limit':50,'offset':x*50}\n",
    "    headers= {'Authorization': 'bearer %s' % api_key}\n",
    "    response=requests.get(url, headers=headers, params=params)\n",
    "    # proceed only if the status code is 200\n",
    "    print('The status code is {}'.format(response.status_code))\n",
    "    d1=response.json() \n",
    "    dict_list.append(d1)\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We separate the key-value of the dictionary to columns names and values using indexing.. and store the cleaned data in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import re\n",
    "s=['coordinates','location']\n",
    "\n",
    "#customized header\n",
    "header =['id', 'alias', 'name', 'image_url', 'is_closed', 'url', 'review_count', 'category alias', 'category title', 'rating', \n",
    "         'coordinates', 'latitude', 'longitude', \n",
    "         'street', 'apt', 'area','city','pincode','country','state','address1','address2',\n",
    "         'phone', 'display_phone', 'distance', 'price']\n",
    "\n",
    "csv_data = []\n",
    "csv_data.append(header)\n",
    "for city in dict_list:\n",
    "    for n, item in enumerate(city):\n",
    "        if item == 'businesses':\n",
    "            for value in city[item]:\n",
    "                row = []\n",
    "                price = ' '\n",
    "                for each in value:\n",
    "                    if each in s:\n",
    "                        for key in value[each]:\n",
    "                            if type(value[each][key]) is list:\n",
    "                                 row.append(\"-\".join(value[each][key]))\n",
    "                            else:\n",
    "                                row.append(value[each][key])\n",
    "                    elif each=='categories':\n",
    "                        for j in value[each][0]:\n",
    "                            row.append(value[each][0][j])\n",
    "                    elif each=='transactions':\n",
    "                        row.append(\"-\".join(value[each]))\n",
    "                    elif each=='price':\n",
    "                        price = value[each]\n",
    "                    else:\n",
    "                        val = re.sub(r'[^\\x00-\\x7F]+','', str(value[each]))\n",
    "                        row.append('\"' + val + '\"')\n",
    "\n",
    "                row.append(price)\n",
    "                #print(row)\n",
    "                csv_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have lists instead list (csv_data), so we can convert them into a csv file.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from csv import DictWriter\n",
    "with open('cafes_mn.csv', 'w', encoding='utf8') as f:\n",
    "    for row in csv_data:\n",
    "        f.write(\",\".join([str(val) for val in row]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have collected listings of restaurants, bars and cafes based on the neighborhood, \n",
    "# let's group them into bars, retsaurants,cafes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All restaurants in NY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 370: expected 26 fields, saw 28\\nSkipping line 631: expected 26 fields, saw 28\\nSkipping line 758: expected 26 fields, saw 28\\n'\n",
      "b'Skipping line 295: expected 26 fields, saw 28\\n'\n",
      "b'Skipping line 862: expected 26 fields, saw 28\\n'\n"
     ]
    }
   ],
   "source": [
    "rest_mn=pd.read_csv('restaurants/rest_mn.csv',error_bad_lines=False)\n",
    "rest_qn=pd.read_csv('restaurants/rest_qn.csv',error_bad_lines=False)\n",
    "rest_bk=pd.read_csv('restaurants/rest_bk.csv',error_bad_lines=False)\n",
    "rest_bx=pd.read_csv('restaurants/rest_bx.csv',error_bad_lines=False)\n",
    "rest_si=pd.read_csv('restaurants/rest_si.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rest=[rest_mn,rest_qn,rest_bk,rest_bx,rest_si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest=pd.concat(df_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total restaurnats collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4995, 26)\n"
     ]
    }
   ],
   "source": [
    "print(rest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of them are unque? It's possible that restaurants in Bronx might be in brooklyn too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059\n"
     ]
    }
   ],
   "source": [
    "print(rest.id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All cafes in NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 299: expected 26 fields, saw 28\\nSkipping line 627: expected 26 fields, saw 28\\nSkipping line 697: expected 26 fields, saw 28\\nSkipping line 854: expected 26 fields, saw 28\\nSkipping line 933: expected 26 fields, saw 27\\n'\n",
      "b'Skipping line 158: expected 26 fields, saw 28\\nSkipping line 663: expected 26 fields, saw 28\\nSkipping line 764: expected 26 fields, saw 28\\n'\n",
      "b'Skipping line 180: expected 26 fields, saw 27\\nSkipping line 378: expected 26 fields, saw 28\\n'\n",
      "b'Skipping line 430: expected 26 fields, saw 28\\nSkipping line 534: expected 26 fields, saw 28\\nSkipping line 997: expected 26 fields, saw 28\\n'\n",
      "b'Skipping line 800: expected 26 fields, saw 27\\n'\n"
     ]
    }
   ],
   "source": [
    "cafes_mn=pd.read_csv('cafes/cafes_mn.csv',error_bad_lines=False)\n",
    "cafes_qn=pd.read_csv('cafes/cafes_qn.csv',error_bad_lines=False)\n",
    "cafes_bk=pd.read_csv('cafes/cafes_bk.csv',error_bad_lines=False)\n",
    "cafes_bx=pd.read_csv('cafes/cafes_bx.csv',error_bad_lines=False)\n",
    "cafes_si=pd.read_csv('cafes/cafes_si.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cafes=[cafes_mn,cafes_qn,cafes_bk,cafes_bx,cafes_si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafes=pd.concat(df_cafes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4986, 26)\n"
     ]
    }
   ],
   "source": [
    "print(cafes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    }
   ],
   "source": [
    "print(cafes.id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All bars in NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 228: expected 26 fields, saw 28\\nSkipping line 476: expected 26 fields, saw 28\\nSkipping line 506: expected 26 fields, saw 28\\nSkipping line 551: expected 26 fields, saw 28\\n'\n",
      "b'Skipping line 4: expected 26 fields, saw 28\\nSkipping line 390: expected 26 fields, saw 28\\n'\n",
      "b'Skipping line 187: expected 26 fields, saw 28\\nSkipping line 487: expected 26 fields, saw 27\\nSkipping line 669: expected 26 fields, saw 27\\nSkipping line 720: expected 26 fields, saw 27\\nSkipping line 813: expected 26 fields, saw 28\\n'\n",
      "b'Skipping line 96: expected 26 fields, saw 28\\nSkipping line 494: expected 26 fields, saw 28\\nSkipping line 608: expected 26 fields, saw 27\\n'\n",
      "b'Skipping line 51: expected 26 fields, saw 27\\nSkipping line 188: expected 26 fields, saw 28\\nSkipping line 560: expected 26 fields, saw 27\\nSkipping line 578: expected 26 fields, saw 28\\nSkipping line 873: expected 26 fields, saw 28\\n'\n"
     ]
    }
   ],
   "source": [
    "bars_mn=pd.read_csv('bars/bars_mn.csv',error_bad_lines=False)\n",
    "bars_qn=pd.read_csv('bars/bars_qn.csv',error_bad_lines=False)\n",
    "bars_bk=pd.read_csv('bars/bars_bk.csv',error_bad_lines=False)\n",
    "bars_bx=pd.read_csv('bars/bars_bx.csv',error_bad_lines=False)\n",
    "bars_si=pd.read_csv('bars/bars_si.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bars=[bars_mn,bars_qn,bars_bk,bars_bx,bars_si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars=pd.concat(df_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4981, 26)\n"
     ]
    }
   ],
   "source": [
    "print(bars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2925\n"
     ]
    }
   ],
   "source": [
    "print(bars.id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's merge all the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=[bars,rest,cafes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total listings collected.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14962, 26)\n"
     ]
    }
   ],
   "source": [
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But how many are unique?? Are bars listed separately? Or Bars are also shown in Restaurants? \n",
    "# DO cafes come in Restaurnats as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8462\n"
     ]
    }
   ],
   "source": [
    "print(final.id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clearly Restaurants, bars and cafes are inter-shown when you searh for either of them.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, let's get rid of duplicate values! Here, we know we have 8462 unique values.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop_duplicates(subset='id',keep=\"last\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8462, 26)\n"
     ]
    }
   ],
   "source": [
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8462\n"
     ]
    }
   ],
   "source": [
    "print(final.id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save this dataframe to csv for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('final_yelp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
